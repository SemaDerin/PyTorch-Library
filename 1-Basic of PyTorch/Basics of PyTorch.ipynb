{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200998a9",
   "metadata": {},
   "source": [
    "# PYTORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449bb1e3",
   "metadata": {},
   "source": [
    "Basics of Pytorch:\n",
    "\n",
    "Açık kaynaklı bir kütüphanedir. Facebook tarafından geliştirilmiştir. Yapay Zeka, Derin Öğrenmede kullanılan bir kütüphanedir. Biligsayarda görme, doğal dil işleme gibi alanlarda kullanılabilir. Keras, Numpy gibi özel bir kütüphanedir. \n",
    "\n",
    "Pytorch bilimsel haesaplamalar yapmak için kullanılan bir kütüphanedir.(Numpy gibi). Fakat diğerlerinden ayıran özellikleri; GPU power kullanmasıdır. (GPU-->Grafik işlmeci birimidir.) Pytorch biligsayarın ekran kartını kullanır. Zamanda esneklik sağlar ve hızlıdır. \n",
    "Debbuging işlemi daha kolaydır. \n",
    "Dinamik grafiklerde performansı iyidir. High level ve Low level Api karışımından ortaya çıkmıştır.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236bf883",
   "metadata": {},
   "source": [
    "# MATRICES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5512fdb",
   "metadata": {},
   "source": [
    "Pytorch da matrislere(array) tensors denir.\n",
    "\n",
    "3*3 array(matris) ===>   3*3 tensor (3D matrisler tensordur)\n",
    "\n",
    "\n",
    "Şimdi numpy kütüphanesi ile array tanımlayalım. Ve numpy'dan pytorch kütüphanesine geçiş yapalım.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c7f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <class 'numpy.ndarray'>\n",
      "Array Shape: (2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy array\n",
    "array = [[1,2,3],[4,5,6]]\n",
    "first_array = np.array(array) # 2x3 array\n",
    "print(\"Array Type: {}\".format(type(first_array))) # type\n",
    "print(\"Array Shape: {}\".format(np.shape(first_array))) # shape\n",
    "print(first_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850efb9",
   "metadata": {},
   "source": [
    "Şimdi de pytorch array implement edelim.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c902a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Type: <built-in method type of Tensor object at 0x00000269C5B19350>\n",
      "Array Shape: torch.Size([2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# import pytorch library\n",
    "import torch\n",
    "\n",
    "# pytorch array\n",
    "tensor = torch.Tensor(array)\n",
    "print(\"Array Type: {}\".format(tensor.type)) # type\n",
    "print(\"Array Shape: {}\".format(tensor.shape)) # shape\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894fb115",
   "metadata": {},
   "source": [
    "Allocation çok kullandığımız methodlardan birisindir. Bellekte yer ayırmak için birlerden oluşan bir array yaratmak. Normalde biz bunu numpyda np.ones() şeklinde yapıyorduk. Pytorch da bunu yapmak istersek de \"torch.ones()\" şeklinde yapabiliyoruz. Memory den yer ayırma işlemidir. \n",
    "\n",
    "Numpyda random sayılar yaratmak istersek np.random.rand() işlemi yaparken bunu torch da \"torch.rand()\" şeklinde yapabiliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "904cd604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "Tensor tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy {}\\n\".format(np.ones((2,3))))\n",
    "\n",
    "#pytorch ones\n",
    "\n",
    "print(\"Tensor {}\\n\".format(torch.ones(2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce3d61",
   "metadata": {},
   "source": [
    "Numpy ile Pytorch arasında geçişler:\n",
    "\n",
    "Numpydan Pytorch'a geçiş işlemleri için:\n",
    "\n",
    "torch.from_numpy()\n",
    "\n",
    "\n",
    "\n",
    "Torchdan Numpy'a geçiş \n",
    "\n",
    "numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "191bb387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "\n",
      "tensor([[0.4090, 0.6657],\n",
      "        [0.4195, 0.4928]], dtype=torch.float64)\n",
      "\n",
      "<class 'numpy.ndarray'> [[0.40898272 0.66566057]\n",
      " [0.41951229 0.4927645 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random numpy array\n",
    "\n",
    "array= np.random.rand(2,2)\n",
    "print(\"{}\\n\".format(type(array),array))\n",
    "\n",
    "\n",
    "#from numpy to tensor\n",
    "from_numpy_to_tensor= torch.from_numpy(array)\n",
    "print(\"{}\\n\".format(from_numpy_to_tensor))\n",
    "\n",
    "#from tensor to numpy\n",
    "\n",
    "tensor= from_numpy_to_tensor\n",
    "from_tensor_to_numpy= tensor.numpy()\n",
    "print(\"{} {}\\n\".format(type(from_tensor_to_numpy),from_tensor_to_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e51f3d",
   "metadata": {},
   "source": [
    "# Basic Math With Pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98379b0a",
   "metadata": {},
   "source": [
    "Resize: view()\n",
    "\n",
    "a ve b birer tensordur.\n",
    "\n",
    "Addition:  torch.add(a,b)====> a+b\n",
    "\n",
    "Subtraction:  torch.sub(a,b)====> a-b\n",
    "\n",
    "Element wise division:  torch.div(a,b)====> a/b\n",
    "\n",
    "Mean:  a.mean()====> Average\n",
    "\n",
    "Standart Deviation:  std: a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b52c4495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Create a tensor\n",
    "\n",
    "tensor= torch.ones(3,3)\n",
    "print(\"\\n\",tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1baf54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Resize\n",
    "\n",
    "print(\"{}{}\\n\".format(tensor.view(9).shape,tensor.view(9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed7e7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Addition\n",
    "\n",
    "print(\"Addition: {}\\n\".format(torch.add(tensor,tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e86197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtraction: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Subtraction\n",
    "\n",
    "print(\"Subtraction: {}\\n\".format(tensor.sub(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2269ce05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element wise multiplication: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Element wise multiplication\n",
    "\n",
    "print(\"Element wise multiplication: {}\\n\".format(torch.mul(tensor,tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83416d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element wise division: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Element wise division\n",
    "\n",
    "print(\"Element wise division: {}\\n\".format(torch.div(tensor,tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb1cc067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.0\n"
     ]
    }
   ],
   "source": [
    "#Mean\n",
    "\n",
    "tensor= torch.Tensor([1,2,3,4,5])\n",
    "print(\"Mean: {}\".format(tensor.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f508328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 1.5811388492584229\n"
     ]
    }
   ],
   "source": [
    "#Standart Deviation(std)\n",
    "\n",
    "print(\"std: {}\".format(tensor.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2be3a1",
   "metadata": {},
   "source": [
    "# VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dccf9e8",
   "metadata": {},
   "source": [
    "Variables: Gradientler  içerisinde toplayan , biriktiren ve depolayan yapılardır.\n",
    "\n",
    "\n",
    "Backward Propagation adımında gradientleri hesaplıyorduk. En optimize hyperparametrelerin ayarlamasında kullandığımız adımdı. Bu gradientleri hesapladığımız zaman bu gradient değerlerini elimizde tutabilmek için variable kullanırız.  Vairiable'ın özelliklerinden biri türev aldığımız zaman bu değerleri içinde tutabilmesidir. \n",
    "\n",
    "Neural network kurabilmek için ve Backward Propagation yapabilmek için variable kullanırız. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d96fc",
   "metadata": {},
   "source": [
    "Gradient değeri Loss fonksiyonunun weightlere göre türevinin alınması. \n",
    "\n",
    "Loss fonksiyonu ise cost fonksiyonlarının toplanmasıydı."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a70aff1",
   "metadata": {},
   "source": [
    "Şimdi bir matematiksel örnek yapalım.\n",
    "\n",
    "Assume we have equation y = x^2\n",
    "\n",
    "Define x = [2,4] variable\n",
    "\n",
    "After calculation we find that y = [4,16] (y = x^2)\n",
    "\n",
    "Recap o equation is that o = (1/2)sum(y) = (1/2)sum(x^2)\n",
    "\n",
    "deriavative of o = x\n",
    "\n",
    "Result is equal to x so gradients are [2,4]\n",
    "\n",
    "Lets implement\n",
    "\n",
    "Yukarıdaki işlemleri açıklayayım. y=x^2 şeklinde bir denklem vardır. x, 2 ve 4 değerlerini alabilmektedir. y'yi hesaplamak için 2 ve 4'ü yerine koymalıyız. y'yi 4 ve 16 buluruz. o = (1/2)sum(y) = (1/2)sum(x^2) satırında o isimli bir variable tanımlanarak toplama işlemi gerçekleştirilmiştir. Sonrasında o'yu kullanarak x'e göre gradient alınır. Yani o'nun x'e göre türevi alınacaktır.\n",
    "\n",
    "Bu işlemleri görsel üzerinden ifade edelim:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b5db0",
   "metadata": {},
   "source": [
    "GRADIENT KULLANIMI :\n",
    "\n",
    "Aklımızda bir neural network yapısı canlandıralım. Nöronlarımız var ve nöronların arasında bağlantı sağlayabilmek için \"weight\" değerlerimiz var. Artı olarak bir de \"bias\" değerlerimiz var. En sonunda bir output değerimiz var ve Output değerimize göre bir \"Cost\" fonksiyonu hesaplıyoruz. Ardından \"tüm costları\" toplayıp bir \"loss\" fonksiyonu elde ediyoruz. Bilindiği üzere \"loss\" fonksiyonu kurduğumuz modelin performansını gözler önüne serer. Eğer ki \"loss\" fonksiyonu minimum değerde değilse hyperparametrelerin yeniden ayarlanması (güncellenmesi) gerekir. Hyperparametrelerimiz dediğimiz değişkenler weigtler ve bias değeridir. Backward Propagation adımında \"loss\" değerini \"weight\" değerine göre türevinin alınmasıdır. Hesapladığımız bu türev \"gradient\" değeridir. Tam da bu işlem sonucu değerleri dpolamak için PyTorch kütüphanesinin içinde tanımlı \"Variable\" adlı veritipini kullanacağız. Değerleri biriktirmiş oluruz. Aslen bunu bir array gibi düşünmek de mümkündür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b584589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import variable from pytorch library\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# define variable\n",
    "var = Variable(torch.ones(3), requires_grad = True)\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb46bf",
   "metadata": {},
   "source": [
    "tensor([1., 1., 1.], requires_grad=True)\n",
    "Yukarıdaki from torch.autograd import Variable kod satırı ile variables import edilmiştir.\n",
    "\n",
    "var = Variable(torch.ones(3), requires_grad = True) satırında ise torch.ones(3) parametresi ile 1'lerden oluşan bir tensör oluşturulmuştur ve Variable'nin içerisine atılmıştır. requires_grad = True parametresi ile gradient bulma işlemi yapılacağı bildirilerek variable'ler ona göre ayarlanmıştır.\n",
    "\n",
    "Şimdi yukarıda yaptığımız matematiksel örneği kodlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "502fec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y =   tensor([ 4., 16.], grad_fn=<PowBackward0>)\n",
      " o =   tensor(10., grad_fn=<MulBackward0>)\n",
      "gradients:  tensor([2., 4.])\n"
     ]
    }
   ],
   "source": [
    "array = [2,4]\n",
    "tensor = torch.Tensor(array)\n",
    "x = Variable(tensor, requires_grad = True)\n",
    "y = x**2\n",
    "print(\" y =  \",y)\n",
    "\n",
    "# recap o equation o = 1/2*sum(y)\n",
    "o = (1/2)*sum(y)\n",
    "print(\" o =  \",o)\n",
    "\n",
    "# backward\n",
    "o.backward() # calculates gradients\n",
    "\n",
    "print(\"gradients: \",x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
